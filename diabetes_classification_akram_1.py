# -*- coding: utf-8 -*-
"""Diabetes Classification Akram 1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/diabetes-classification-akram-1-fcb05b1c-5817-45aa-96fe-5991ca3b6000.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240208/auto/storage/goog4_request%26X-Goog-Date%3D20240208T090833Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D89e87aeade80014ed9a415d2d0b45be233f41a7d12d0aafaaf0dfb8e832a70a33d6da69c11389cd814ca31a4d069d12a73af0209f73761dcdee89d095a7ef3a51e28a8b6ae374e98266076c0b2fc83efdde1de19953c8dfe80bd386eedf2a130978c3afaf61972e9c20c06cc724740b79abfc19b405feb26a5c968c1a6eb1f84cc3a6d0b908f1f0f288501b776a308068843b4189cf2619ae730e6308a16e566e81d03b92c582fb14783cd4d64a871c8b14fbb4601ba88f76a19a9ee6cc1bc563a6b82042202a4c5659968b0f8759f8ced8589f6a6069f9badf1da588144983109bc7e99236eeb27d036051ef6034a8ebbe2af4ea9b444451751d321dd28f9c1
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'predict-diabities:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2619659%2F4476380%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240208%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240208T090832Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2b5c4a1867fdc7d3014739c1ea275dc831cbd50bf6db916407b93691e206fd45858a24294259f843dd8a04e0f11853e0ac1849027f4cc8c08f1550370c2e55c913338935443d1ed56a66b9df8a47aa024daada2ab60d440197378196e0d8e16f31d03c09edbb860d6cf1212b0651c4ed4802284ae97840df302cac3378e6552ff23491ed6c94a777a8f1dbd1c1b4714ec99010025b8f02f11f4f10d2a6913f60c56373898fbb264635c2ffcf232a2b271eb0ed57d866b42d77e9ee9343c0a0bf87be1e31b5ceab20469e41cac16493e6c053143f2c30200b1a882999c71eb56b861986ba3af5cb4329a2d727f19023d3d1521f0ad9763d19027462ad4e70eea4'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import warnings
warnings.filterwarnings('ignore')
import pandas as pd

df = pd.read_csv('/kaggle/input/predict-diabities/diabetes.csv')
df.head()

df.info()

df.describe()

import matplotlib.pyplot as plt
import seaborn as sns

correlation = df.corr()
plt.figure(figsize=(10,8))
sns.heatmap(correlation, cbar=True, square=True, fmt='.1f', annot=True, annot_kws={'size':8}, cmap='Blues')

X = df.drop('Outcome', axis=1)
y = df['Outcome']

"""# Handling outliers in X"""

columns_names = X.columns

# that function suppress for any outlier
def outlier_thresholds(dataframe,variable,q1=0.25,q3=0.75):
    quartile1 = dataframe[variable].quantile(q1)
    quartile3 = dataframe[variable].quantile(q3)
    quantile_range = quartile3 - quartile1
    up_limit = quartile3 + 1.5 * quantile_range
    low_limit = quartile1 - 1.5 * quantile_range
    return up_limit, low_limit
# if has any outlier we make replace with it
def replace_with_outlier(dataframe,variable):
    up_limit, low_limit = outlier_thresholds(dataframe,variable)
    dataframe.loc[dataframe[variable] < low_limit, variable] = low_limit
    dataframe.loc[dataframe[variable] > up_limit, variable] = up_limit

# check outlier function
def check_outlier(dataframe,col_name):
    up_limit, low_limit = outlier_thresholds(dataframe, col_name)
    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):
        return True
    else:
        return False

# Check outliers
for col in columns_names:
    print((col))
    print(check_outlier(X,col))
    print('================')

# handel outliers
# col1 = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness']
for col in columns_names:
    # outlier_thresholds(df,col)
    replace_with_outlier(X,col)

# Check outliers
for col in columns_names:
    print((col))
    print(check_outlier(X,col))
    print('================')

"""# Check imbalanced Outcome"""

plt.figure(figsize=(6, 4))
df['Outcome'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('Imbalanced Column Outcome')
plt.xlabel('Outcome')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

from imblearn.over_sampling import SMOTE

x_res, y_res = SMOTE().fit_resample(X, y)

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(x_res, y_res, test_size=0.2, random_state=42)

"""# Feature Scaling"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

X_train = scaler.fit_transform(X_train)
X_val= scaler.fit_transform(X_val)

"""# Create LogisticRegression model"""

from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression()
log_model.fit(X_train, y_train)
ypred1 = log_model.predict(X_val)

from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score

acc0 = roc_auc_score(y_val, ypred1)
print('roc_auc_score: ', acc0)
acc1 = accuracy_score(y_val, ypred1)
print('accuracy_score: ', acc1)
acc2 = precision_score(y_val, ypred1)
print('precision_score: ', acc2)
acc3 = recall_score(y_val, ypred1)
print('recall_score: ', acc3)
acc4 = f1_score(y_val, ypred1)
print('f1_score: ', acc4)

"""# Create SVC model"""

from sklearn.svm import SVC

svc_model = SVC()
svc_model.fit(X_train, y_train)
ypred2 = svc_model.predict(X_val)

acc0 = roc_auc_score(y_val, ypred2)
print('roc_auc_score: ', acc0)
acc1 = accuracy_score(y_val, ypred2)
print('accuracy_score: ', acc1)
acc2 = precision_score(y_val, ypred2)
print('precision_score: ', acc2)
acc3 = recall_score(y_val, ypred2)
print('recall_score: ', acc3)
acc4 = f1_score(y_val, ypred2)
print('f1_score: ', acc4)

"""# Create RandomForestClassifier model"""

from sklearn.ensemble import RandomForestClassifier

rfc_model = RandomForestClassifier()
rfc_model.fit(X_train, y_train)
ypred3 = rfc_model.predict(X_val)

acc0 = roc_auc_score(y_val, ypred3)
print('roc_auc_score: ', acc0)
acc1 = accuracy_score(y_val, ypred3)
print('accuracy_score: ', acc1)
acc2 = precision_score(y_val, ypred3)
print('precision_score: ', acc2)
acc3 = recall_score(y_val, ypred3)
print('recall_score: ', acc3)
acc4 = f1_score(y_val, ypred3)
print('f1_score: ', acc4)

"""# Create XGBClassifier model"""

from xgboost import XGBClassifier

xgc_model = XGBClassifier()
xgc_model.fit(X_train, y_train)
ypred4 = xgc_model.predict(X_val)

acc0 = roc_auc_score(y_val, ypred4)
print('roc_auc_score: ', acc0)
acc1 = accuracy_score(y_val, ypred4)
print('accuracy_score: ', acc1)
acc2 = precision_score(y_val, ypred4)
print('precision_score: ', acc2)
acc3 = recall_score(y_val, ypred4)
print('recall_score: ', acc3)
acc4 = f1_score(y_val, ypred4)
print('f1_score: ', acc4)

models_acc = pd.DataFrame({'Models': ['LogisticRegression', 'SVC', 'RandomForestClassifier', 'XGBClassifier'],
                           'roc_auc_score': [roc_auc_score(y_val, ypred1),
                                             roc_auc_score(y_val, ypred2),
                                             roc_auc_score(y_val, ypred3),
                                             roc_auc_score(y_val, ypred4)
                                             ],
                           'accuracy_score': [accuracy_score(y_val, ypred1),
                                              accuracy_score(y_val, ypred2),
                                              accuracy_score(y_val, ypred3),
                                              accuracy_score(y_val, ypred4)
                                              ],
                           'precision_score': [precision_score(y_val, ypred1),
                                              precision_score(y_val, ypred2),
                                              precision_score(y_val, ypred3),
                                              precision_score(y_val, ypred4)
                                              ],
                           'recall_score':    [recall_score(y_val, ypred1),
                                              recall_score(y_val, ypred2),
                                              recall_score(y_val, ypred3),
                                              recall_score(y_val, ypred4)
                                              ],
                           'f1_score':        [f1_score(y_val, ypred1),
                                              f1_score(y_val, ypred2),
                                              f1_score(y_val, ypred3),
                                              f1_score(y_val, ypred4)
                                              ]
                          })

models_acc